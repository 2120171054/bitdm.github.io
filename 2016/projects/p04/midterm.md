## 阶段报告：
### 项目简介：
+ 文本有10个类别，环境、计算机、教育、交通、经济、军事、体育、医药、艺术、政治，通过对每种类别的每篇文章进行预处理，分词，去除停用词，统计tf-idf，生成词袋模型，在利用标签进行训练，训练方法为knn，然后对没有标签的文本进行预测分类。

+ 主题抽取，对于每种类别，统计词袋模型中靠前的几个单词，则可以描述该主题的主要内容。

### 阶段工作：
文本分类为10个类别，每个类别中有200篇文章，每篇文章大概3000个字，属于长文本分类，对于每个类别，提取其中的主题内容。

### 一、预处理阶段
首先需要对文本进行预处理，具体包括：
> 1)去掉不相关的header，footer以及其他注释信息；

> 2)去除文本分行标志的"\r\n"，合并为一个段落；

> 3)将处理好的文本放到新目录下，目录结构和之前的结构相同。

### 二、分词
将上一步进行预处理的文本进行分词，分词后放到新目录下，目录结构依然保持和之前的目录结构一致。

### 三、将预处理的文本进行打包
在这一阶段，我们主要是实现一个训练用预料数据结构，为做计算tf-idf向量空间模型做准备。

1、首先定于训练集的数据结构：

    定义训练集对象：data_set

    使用python的bunch类提供一中(key,value)的对象形式

    Target_name:所有分类集名称列表

    Label：每个语篇定义分类标签列表

    Filenames：分词后语篇路径

    Contents：分词后语篇内容

2、从分词语料库中将所需要的信息读入训练集的数据结构中

3、将训练集持久化为一个数据对象文件

4、读出数据对象文件，验证持久化的正确性


注：这一阶段，由于实验还未完全做完，就不做实验的展示了，实验的最终结果会在最终报告的实验部分展示。
