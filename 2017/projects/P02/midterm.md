## 数据挖掘大作业阶段报告 ##
#### 选题：《基于聚类算法的高价值目标客户分析——以某航空公司为例》 ####

**小组成员**

- 石鹏飞
- 王崛飞
- 于大江
- 聂玉冰
- 孙灿

### 简介 ###
聚类分析以相似性为基础，在一个聚类中的模式之间比不在同一聚类中的模式之间具有更多的相似性。
在商业上，聚类可以帮助市场分析人员从消费者数据库中区分出不同的消费群体来，并且概括出每一类消费者的消费模式或者说习惯。它作为数据挖掘中的一个模块，可以作为一个单独的工具以发现数据库中分布的一些深层的信息，并且概括出每一类的特点，或者把注意力放在某一个特定的类上以作进一步的分析；并且，聚类分析也可以作为数据挖掘算法中其他分析算法的一个预处理步骤。

作为企业的核心问题之一——客户关系管理，其关键是针对不同类别的客户指定与其相对应的个性化服务方案，采取不同的营销策略，将有限资源集中于高价值客户，从而实现利润最大化目标。我们以某航空公司为例，通过采用聚类算法对其客户进行分群，旨在建立合理的客户价值评估模型，并分析不同客户群的特点，提供相对应的商业策略。

### 问题陈述 ###
#### 问题场景 ####
航空公司的市场竞争非常激烈，尤其在当前的信息社会，能够充分利用航空信息数据，挖掘客户信息，区分出一般及低价值客户、重要挽留客户、重要保持客户和重要发展客户等，可以针对每类人，制定不同的营销策略，一方面可以增加用户粘性，另一方面也可以增加公司的盈利，从而达到公司的商业目的。

我们客户分析主要选取五个指标：客户关系长度L、消费时间间隔R、消费频率F、飞行里程M和折扣系数的平均值C这是进行聚类分析的主要参考信息。
我们需要根据以上五个比较重要的指标来得到一些结论：

1. 首先是聚类。把消费行为相似的用户聚到同一个模块中。
 
2. 然后是为每个模块，总结用户消费规律，总结客户价值与需求
 
3. 最后为每个类别制定相应的营销策略，从而为公司达到预期的效益

#### 数据集 ####
数据集为航空信息属性表。属性表主要包括三类信息，分别为客户基本信息、乘机信息和积分信息。
客户基本信息包括：会员卡号、入会时间、第一次飞行时间、性别、会员卡级别、工作地城市、工作地所在省份、工作地所在国家和年龄。

乘机信息包括：观测窗口内的飞行次数、观测窗口的结束时间、最后一次乘机时间至观测窗口结束时长、平均折扣率、观测窗口的票价收入、观测窗口的总飞行公里数、末次飞行日期、平均乘机时间间隔、最大乘机间隔。

积分信息包括：计分兑换次数、总精英计分、促销积分、合作伙伴积分、总累计积分、非乘机的积分变动次数和总基本积分。

航空信息数据表如下图所示。我们的数据是以CVS格式文件存储的。数据表中的信息整合了以上介绍的三个类别的信息。我们主要对下图所示数据进行处理与分析。航空信息数据表如下图所示。
![](http://i.imgur.com/3JfUTmK.png)
上图第一行是属性名称，各个属性的英文对应的中文和备注如下图所示。第二行到最后一行为具体数据。每一列代表一个属性。
![](http://i.imgur.com/uZ1KByA.png)
#### 预期结果 ####
我们的模型的核心是聚类分析，所以结果为依据航空信息数据表，对客户做出聚类的结果。我们期望把客户分为5个类别，所以得到的结果为类别和客户的对应关系以及每个类别的消费属性信息，包括客户关系长度L、消费时间间隔R、消费频率F、飞行里程M和折扣系数的平均值C。

依据聚类结果我们还需要对用户价值进行分类和营销策略的制定。这是对实验结果的最终预期。
#### 评价指标 ####
紧凑度。紧凑度是衡量一个簇内样本点之间的是否足够紧凑的，包括到簇中心的平均距离、方差。

分离度。分离度是衡量该样本是否到其他簇的距离是否足够的远。S_Dbw算法：这种算法是通过一种密度衡量公式来评价分离的好坏的。从所有的簇中心中至少有一个密度值要大于midpoint的密度值，然后通过SD算法的紧凑度算法计算出一个权重值判断聚类的好坏。

在实际中，可以通过计算航班的效益来评价此模型及营销策略是否有效。

### 目前进展 ###
目前完成的工作是数据抽取、数据探索分析和数据的预处理。
#### 数据抽取 ####
历史数据：以2014-03-31为结束时间，选取宽度为两年的时间段作为分析观测窗口，抽取观测窗口内有乘机记录的所有客户的详细数据。

增量数据：以后续新增数据中最新的时间点作为结束时间，采用上述方法进行抽取。
#### 数据探索分析 ####
主要是处理缺失值和异常值。查找每个属性中空值个数、最大值与最小值。

对数据文件进行一次遍历，找出每个属性中空值个数、最大值与最小值。输出如下图所示。
![](http://i.imgur.com/TOxt6tO.png)
#### 数据预处理 ####
1. 数据清洗。由于数据有缺失值和异常值的记录所占比例较小，所以可以直接删除掉。
2. 属性规约。数据原始属性有44个，其中不乏与LRFMC指标不相关属性和相关属性，比如会员卡号和性别等，这些属性可以过滤掉。
3. 数据变换。数据变换是将数据转换成“适当的”格式，以适应挖掘任务和算法的需要。

经过数据清洗、属性规约和基本的数据变换后，待处理数据只剩6个属性，结果如下图所示。
![](http://i.imgur.com/ZCI9Gjl.png)

### 下一步计划 ###

模型构建与模型应用

用K-Means聚类算法对客户数据进行分群，聚成5类。K-Means聚类算法位于Scikit-learn库下的聚类子库（sklearn cluster）。

依据计算出的LRFMC指标，结合业务对客户做出价值分析。
